{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment, Dataset\n",
    "from azureml.core.runconfig import RunConfiguration, MpiConfiguration\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Workspace.create(name='benchy', subscription_id='6560575d-fa06-4e7d-95fb-f962e74efd7a', resource_group='copeters_benchmarking')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"https://azureopendatastorage.blob.core.windows.net/isdweatherdatacontainer/ISDWeather/*/*/*.parquet\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetFiles\"\n",
       "  ],\n",
       "  \"registration\": {\n",
       "    \"id\": \"5a3248d1-e0ee-49b1-8e2b-d5167afa0e6c\",\n",
       "    \"name\": \"weather-files\",\n",
       "    \"version\": 1,\n",
       "    \"workspace\": \"Workspace.create(name='benchy', subscription_id='6560575d-fa06-4e7d-95fb-f962e74efd7a', resource_group='copeters_benchmarking')\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'weather-files' not in ws.datasets:\n",
    "    ds = Dataset.File.from_files('https://azureopendatastorage.blob.core.windows.net/isdweatherdatacontainer/ISDWeather/*/*/*.parquet', validate=False)\n",
    "    ds = ds.register(ws, 'weather-files')\n",
    "else:\n",
    "    ds = ws.datasets['weather-files']\n",
    "    \n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {compute_name: (vCPUs, RAM, DISK, $/hr)}\n",
    "\n",
    "MAX_VCPUS = 1000\n",
    "MIN_RAM   = 100\n",
    "MAX_RAM   = 1000\n",
    "\n",
    "computes = {\n",
    "    #'STANDARD_D12'    : (4,  28,  200,  .386),\n",
    "    'STANDARD_D12_V2' : (4,  28,  200,  .370),\n",
    "    #'STANDARD_D13'    : (8,  56,  400,  .771),\n",
    "    'STANDARD_D13_V2' : (8,  56,  400,  .741),\n",
    "    'STANDARD_DS12_V2': (4,  28,   56,  .370),\n",
    "    'STANDARD_DS13_V2': (8,  56,  112,  .741),\n",
    "    'STANDARD_DS15_V2': (20, 140, 280, 1.852),\n",
    "    'STANDARD_DS5_V2' : (16,  56, 112, 1.170),\n",
    "    #'STANDARD_F32S_V2': (32, 64,  256, 1.360)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_sizes = list(computes)\n",
    "nodeses  = list(reversed([1, 2, 5, 10, 20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D12-V2 already exists\n",
      "D13-V2 already exists\n",
      "DS12-V2 already exists\n",
      "DS13-V2 already exists\n",
      "DS15-V2 already exists\n",
      "DS5-V2 already exists\n"
     ]
    }
   ],
   "source": [
    "for vm_size in vm_sizes:\n",
    "    ct_name = vm_size.replace('STANDARD_', '').replace('_', '-')\n",
    "    if ct_name not in ws.compute_targets:\n",
    "        # create config for Azure ML cluster\n",
    "        # change properties as needed\n",
    "        # final default values for blog tbd - need to benchmark and minimize cost\n",
    "        config = AmlCompute.provisioning_configuration(\n",
    "                 vm_size                 = vm_size,\n",
    "                 max_nodes               = max(nodeses),\n",
    "                 vnet_resourcegroup_name = ws.resource_group,\n",
    "                 vnet_name               = 'bench-vnet',\n",
    "                 subnet_name             = 'default'\n",
    "        )\n",
    "\n",
    "        ct = ComputeTarget.create(ws, ct_name, config)\n",
    "        ct.wait_for_completion(show_output=True)    \n",
    "    else:\n",
    "        print(f'{ct_name} already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nodes: 20\n",
      "\t| VM Size - STANDARD_D12_V2  | vCPUs - 80 | RAM - 560GB | WAGE - $7.4/hr |\n",
      "\t\tSubmitting run...\n",
      "\t\tRun submitted...\n",
      "\t| VM Size - STANDARD_DS12_V2 | vCPUs - 80 | RAM - 560GB | WAGE - $7.4/hr |\n",
      "\t\tSubmitting run...\n",
      "\t\tRun submitted...\n",
      "\n",
      "Nodes: 10\n",
      "\t| VM Size - STANDARD_D12_V2  | vCPUs - 40 | RAM - 280GB | WAGE - $3.7/hr |\n",
      "\t\tSubmitting run...\n",
      "\t\tRun submitted...\n",
      "\t| VM Size - STANDARD_D13_V2  | vCPUs - 80 | RAM - 560GB | WAGE - $7.41/hr |\n",
      "\t\tSubmitting run...\n",
      "\t\tRun submitted...\n",
      "\t| VM Size - STANDARD_DS12_V2 | vCPUs - 40 | RAM - 280GB | WAGE - $3.7/hr |\n",
      "\t\tSubmitting run...\n",
      "\t\tRun submitted...\n",
      "\t| VM Size - STANDARD_DS13_V2 | vCPUs - 80 | RAM - 560GB | WAGE - $7.41/hr |\n",
      "\t\tSubmitting run...\n",
      "\t\tRun submitted...\n",
      "\t| VM Size - STANDARD_DS5_V2  | vCPUs - 160 | RAM - 560GB | WAGE - $11.7/hr |\n",
      "\t\tSubmitting run...\n",
      "\t\tRun submitted...\n",
      "\n",
      "Nodes: 5\n",
      "\t| VM Size - STANDARD_D12_V2  | vCPUs - 20 | RAM - 140GB | WAGE - $1.85/hr |\n",
      "\t\tSubmitting run...\n",
      "\t\tRun submitted...\n",
      "\t| VM Size - STANDARD_D13_V2  | vCPUs - 40 | RAM - 280GB | WAGE - $3.705/hr |\n",
      "\t\tSubmitting run...\n",
      "\t\tRun submitted...\n",
      "\t| VM Size - STANDARD_DS12_V2 | vCPUs - 20 | RAM - 140GB | WAGE - $1.85/hr |\n",
      "\t\tSubmitting run...\n",
      "\t\tRun submitted...\n",
      "\t| VM Size - STANDARD_DS13_V2 | vCPUs - 40 | RAM - 280GB | WAGE - $3.705/hr |\n",
      "\t\tSubmitting run...\n",
      "\t\tRun submitted...\n",
      "\t| VM Size - STANDARD_DS15_V2 | vCPUs - 100 | RAM - 700GB | WAGE - $9.26/hr |\n",
      "\t\tSubmitting run...\n",
      "\t\tRun submitted...\n",
      "\t| VM Size - STANDARD_DS5_V2  | vCPUs - 80 | RAM - 280GB | WAGE - $5.85/hr |\n",
      "\t\tSubmitting run...\n",
      "\t\tRun submitted...\n",
      "\n",
      "Nodes: 2\n",
      "\t| VM Size - STANDARD_D13_V2  | vCPUs - 16 | RAM - 112GB | WAGE - $1.482/hr |\n",
      "\t\tSubmitting run...\n",
      "\t\tRun submitted...\n",
      "\t| VM Size - STANDARD_DS13_V2 | vCPUs - 16 | RAM - 112GB | WAGE - $1.482/hr |\n",
      "\t\tSubmitting run...\n",
      "\t\tRun submitted...\n",
      "\t| VM Size - STANDARD_DS15_V2 | vCPUs - 40 | RAM - 280GB | WAGE - $3.704/hr |\n",
      "\t\tSubmitting run...\n",
      "\t\tRun submitted...\n",
      "\t| VM Size - STANDARD_DS5_V2  | vCPUs - 32 | RAM - 112GB | WAGE - $2.34/hr |\n",
      "\t\tSubmitting run...\n",
      "\t\tRun submitted...\n",
      "\n",
      "Nodes: 1\n",
      "\t| VM Size - STANDARD_DS15_V2 | vCPUs - 20 | RAM - 140GB | WAGE - $1.852/hr |\n",
      "\t\tSubmitting run...\n",
      "\t\tRun submitted...\n"
     ]
    }
   ],
   "source": [
    "exp = Experiment(ws, 'describe')\n",
    "\n",
    "for nodes in nodeses:\n",
    "    print(f'\\nNodes: {nodes}')\n",
    "    for vm_size in vm_sizes:\n",
    "        ct_name = vm_size.replace('STANDARD_', '').replace('_', '-')\n",
    "        \n",
    "        vcpus, ram, disk, wage = computes[vm_size]\n",
    "        \n",
    "        vcpus *= nodes\n",
    "        ram   *= nodes\n",
    "        disk  *= nodes\n",
    "        wage  *= nodes\n",
    "        \n",
    "        if vcpus < MAX_VCPUS and ram > MIN_RAM and ram < MAX_RAM:\n",
    "            print(f'\\t| VM Size - {vm_size:16} | vCPUs - {vcpus} | RAM - {ram}GB | WAGE - ${round(wage, 3)}/hr |')\n",
    "            \n",
    "            est = Estimator('code', \n",
    "                            compute_target=ws.compute_targets[ct_name], \n",
    "                            entry_script='runDask.py', \n",
    "                            conda_dependencies_file='environment.yml', \n",
    "                            #script_params={'--datastore': ws.get_default_datastore()},\n",
    "                            inputs=[ds.as_named_input('weather').as_download('/tmp/noaa')],\n",
    "                            node_count=nodes,\n",
    "                            distributed_training=MpiConfiguration())\n",
    "            \n",
    "            print('\\t\\tSubmitting run...')\n",
    "            run = exp.submit(est)\n",
    "            run.log('nodes', nodes)\n",
    "            run.log('vm_size', vm_size)\n",
    "            run.log('vcpus', vcpus)\n",
    "            run.log('ram', ram)\n",
    "            run.log('disk', disk)\n",
    "            run.log('wage', wage)\n",
    "            print('\\t\\tRun submitted...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>describe</td><td>benchy</td><td><a href=\"https://ml.azure.com/experiments/describe?wsid=/subscriptions/6560575d-fa06-4e7d-95fb-f962e74efd7a/resourcegroups/copeters_benchmarking/workspaces/benchy\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Experiment(Name: describe,\n",
       "Workspace: benchy)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp = Experiment(ws, 'describe')\n",
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "describe_1576980205_e36001e3\n",
      "describe_1576979922_b2dd4f0a\n",
      "describe_1576980259_b3689bd0\n",
      "describe_1576980099_bd38c24f\n",
      "describe_1576980368_4a5c951c\n",
      "describe_1576980012_2fd2d782\n",
      "describe_1576980233_12d16c65\n",
      "describe_1576980152_554b09c7\n",
      "describe_1576979985_287f17a1\n",
      "describe_1576980313_1b85b1de\n",
      "describe_1576980391_238f6d7a\n",
      "Total cost: $0.6873880436007181\n",
      "describe_1576980340_2c65a67a\n",
      "describe_1576980067_15046e2c\n",
      "describe_1576979958_809cdeb8\n",
      "describe_1576980285_d6f380a2\n",
      "describe_1576980179_63ccf9b6\n",
      "describe_1576980125_ca10b665\n",
      "describe_1576980040_8a1a0f5b\n"
     ]
    }
   ],
   "source": [
    "for run in list(exp.get_runs()):\n",
    "    runid   = run.id\n",
    "    print(runid)\n",
    "    metrics = run.get_metrics()\n",
    "    nodes   = metrics['nodes']\n",
    "    vm_size = metrics['vm_size']\n",
    "    vcpus   = metrics['vcpus']\n",
    "    wage    = metrics['wage']\n",
    "    ram     = metrics['ram']\n",
    "    disk    = metrics['disk']\n",
    "\n",
    "    if run.get_status() == 'Completed' and 'duration' in metrics and 'cost' not in metrics:\n",
    "        cost = metrics['duration']*wage/60/60\n",
    "        print(f'Total cost: ${cost}')\n",
    "        run.log('cost', f'${round(cost, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nodes': 20,\n",
       " 'vm_size': 'STANDARD_D12_V2',\n",
       " 'vcpus': 80,\n",
       " 'ram': 560,\n",
       " 'disk': 4000,\n",
       " 'wage': 7.4}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kill clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ct in ws.compute_targets:\n",
    "    #ws.compute_targets[ct].delete()\n",
    "    pass\n",
    "\n",
    "ws.compute_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cancel runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Experiment(ws, 'test6')\n",
    "\n",
    "for run in exp.get_runs():\n",
    "    if run.get_status() == 'Running':\n",
    "        run.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aml] *",
   "language": "python",
   "name": "conda-env-aml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
